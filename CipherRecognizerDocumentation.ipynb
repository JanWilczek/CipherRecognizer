{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CipherRecognizer\n",
    "#### Jan Jasiński & Jan Wilczek\n",
    "\n",
    "###### Technologia Mowy AGH 2017\n",
    "\n",
    "### Wstęp\n",
    "\n",
    "Celem projektu \"CipherRecognizer\" jest stworzenie prostego systemu rozpoznawania nagranych nazw cyfr zaimplementowany w języku Python.\n",
    "Link do repozytorium: https://github.com/Jasinsk/CipherRecognizer\n",
    "\n",
    "### Raport 1 (16.11.17-23.11.17)\n",
    "\n",
    "1. Założenia\n",
    "\n",
    "   Do naszego projektu wybraliśmy parametryzację MFCC sygnału mowy - do jej wyznaczania używamy biblioteki python_speech_features.\n",
    "\n",
    "   Jako klasyfikatora chcemy użyć odpowiednio wyszkolonej sieci neuronowej. Zdecydowaliśmy się na klasyfikator MLPClassifier z biblioteki sklearn.neural_network. Na jego właściwym ustawieniu opierać się będzie znaczna część procesu dopasowania modelu nauki klasyfikatora.\n",
    "   \n",
    "   Wejściem sieci neuronowej będzie superwektor o długości 13 + 13x13 = 182, złożony z uśrednionego po czasie wektora parametrów MFCC wraz z kolejnymi rzędami macierzy kowariancji ustawionymi jeden za drugim w ciąg.\n",
    "   \n",
    "2. Architektura systemu\n",
    "\n",
    "   Cały nasz projekt opiera się na klasach. Obecnie ich lista wraz z metodami wygląda następująco:\n",
    "   \n",
    "   A. `GlobalParameters` (niezaimplementowana)\n",
    "      - klasa w modelu singleton zawierająca wszystkie parametry, którymi można regulować (dostrajać) system.\n",
    "      \n",
    "   B. `WaveFile` - klasa odpowiedzialna za odczytanie danych z pliku wave.\n",
    "    * `__init__(self, filepath)`  - konstruktor, filepath określa ścieżkę dostępu do danego pliku z nagraniem cyfry.\n",
    "    * `data(self, normalize=True)` - zwraca dane z pliku audio jako listę z wartościami typu float w zakresie <-1,1>.\n",
    "    \n",
    "   C. `MFCCParametrizer` - klasa odpowiedzialna za parametryzację MFCC sygnału.\n",
    "    * `__init__(self,winlen=0.025,winstep=0.01,numcep=13,nfilt=26,nfft=512,preemph=0.97,ceplifter=22,               appendEnergy=True)` - konstruktor ustawiający parametry wyznaczania MFCC zgodnie z kolejnymi argumentami.\n",
    "    * `parameters(self, signal, samplerate)` - zwraca macierz wyznaczonych parametrów z podanego sygnału.\n",
    "\t* `super_vector(self, signal, samplerate)` - zwraca superwektor parametrów wyznaczonych na podstawie danego sygnału.\n",
    "    \n",
    "   D. `ANNClassifier` - klasa będąca opakowaniem dla sieci neuronowej.\n",
    "    * `__init__(self, nb_hidden_layers, nb_neurons_in_layer, activation_function='relu', solver='lbfgs', nb_iterations=200)` - konstruktor klasyfikatora z zadanymi parametrami. W przyszłości zmienimy nieco tę implementację, żeby w każdej warstwie sieci nie było tyle samo neuronów.\n",
    "    * `train(self, training_input_data, training_output_data)` - wytrenowuje model podając kolejne wektory z wejściami i odpowiadające im wyjścia.\n",
    "    * `predict(self, test_input_data)` - oblicza logarytmiczne prawdopodobieństwa każdej klasy (w naszym przypadku jest 10 klas odpowiadających 10 cyfrom) i zwraca ich wektor.\n",
    "    \n",
    "   E. `ResultHolder` - klasa odpowiadająca za zbieranie wyników (prawdopodobieństw) w testach kros-walidacji i obliczania skuteczności dla zadanych parametrów. Rezultaty można następnie eksportować do pliku .xls.\n",
    "    * `__init__(self, classes)` - konstruktor przekazujący nazwy klas. Przekazywanym wektorem klas powinien być `ANNClassifier.MLPClassifier.classes_`.\n",
    "    * `add_result(self, prediction_vector, correct_result)` - dodaje kolejne wyniki otrzymywane w wyniku wywołania metody `predict()` klasy `ANNClassifier` i zapisuje wraz z przekazanym poprawnym wynikiem.\n",
    "    * `error_rate(self)`- oblicza procent błędów wszystkich dodanych wyników.\n",
    "    * `write_results_to_excel_file(self, filename, sheet)` - wypisuje wszystkie wyniki wraz z ich poprawnymi odpowiedziami, poprawnością (za odpowiedź uznaje się klasę z największym prawdopodobieństwem) oraz końcowy procent błędów do pliku .xls.\n",
    "    * `__is_correct(self, index)` - prywatna metoda zwracająca wartość logiczną mówiącą o tym, czy odpowiedź wyniku o podanym indeksie jest poprawna.\n",
    "  \n",
    "   F. `Recognizer` (niezaimplementowana) - główna klasa odpowiedzialna za pętle testów, zmianę parametrów itp. Jej metody nie są jeszcze sprecyzowane.\n",
    "\n",
    "   G. `ConfigurationManager` (niezaimplementowana) - klasa służąca do generowania konfiguracji w sposób deterministyczny (dla przykładu: jeśli podamy liczbę plików testowych równą 10 każde wywołanie metody `__generate_configurations` powinno wygenerować te same konfiguracje).\n",
    "    * `__init__(self, foldername)` - konstruktor z przekazywaną nazwą folderu z plikami audio.\n",
    "    * `__generate_configurations(self, nb_test_files)` - generuje konfiguracje do kros-walidacji o zadanej liczbie testów w każdym zbiorze.\n",
    "    * `nb_configurations(self)` - zwraca liczbę konfiguracji.\n",
    "    * `test_data(self, configuration_id)` - zwraca ścieżki plików wybrane do testu w konfiguracji o danym indeksie.\n",
    "    * `training_data(self, configuration_id)` - zwraca ścieżki plików wybrane do treningu w konfiguracji o danym indeksie.\n",
    "    * `output_configurations_to_file(self, filename)` - wypisuje konfiguracje do pliku.\n",
    "   \n",
    "3. Postęp prac\n",
    " \n",
    "    Udało nam się do tej pory zaimplementować wstępnie klasy ANNClassifier, MFCCParametrizer, ResultHandler i WavFile wraz z testami. Oznacza to, że w praktyce jesteśmy w stanie wczytać plik, otworzyć go, wyliczyć parametry MFCC i następnie wprowadzić je jako dane wejściowe sieci neuronowej. Klasy te są gotowe do zastosowania we wstępnej implementacji pętli treningowo-testowej służącej do wybrania odpowiednich parametrów systemu. Kiedy uda nam się połączyc ze sobą wsystkie te funkcje to będziemy musieli jeszcze zaimplementować jakąś formę automatyzacji trenowania i testowania systemu, gdyż obecnie musielibyśmy wszystkie ścieżki plików wprowadzać ręcznie. Warto byłoby także stworzyć mechanizm zapisywania do pliku wartości parametrów otrzymanych po dokonaniu MFCC, żeby móc wczytywać te pliki przy kolejnych wykonaniach programu, aby uniknąć każdorazowego wyliczania ich z plików dźwiękowych. \n",
    "    Największą trudnością będzie dobór wielkości i liczby warstw w sieci neuronowej, ponieważ brak nam doświadczenia w tej dziedzinie. Spodziewamy się zatem, iż będzie to etap wymagający znaczącej ilości prób i błędów. Zależnie od potrzeby możliwe jest, iż do wstępnej optymalizacji wykorzystamy funkcję, która będzie zmieniać te paramtery sieci, trenować ją i następnie testować, co pozwoli nam zobaczyć jak dla zmian tych parametrów będzie zmieniać się prawidłowość otrzymywanej odpowiedzi przy testowaniu systemu. \n",
    "    Dotychczas nie spotkaliśmy sie z nadmiernymi trudnościami jeżeli chodzi o pisane programy. Wszelkie problemy udawało się rozwiązać wspólnymi siłami. Nie mielimy jednak jeszcze możliwości sprawdzenia klasy ANNClasifier, która w razie ewentualnych błędów przy wykonywaniu mogłaby sprawić najwięcej problemu w związku z faktem, iż żaden z nas nigdy nie korzystał z sieci neuronowych i w pisaniu musimy opierać się wyłącznie na dokumentacji oraz poradach z Internetu.\n",
    "    Obecnie planujemy aby do końca tego tygodnia pracy mieć zakończone i poprawione wszystkie poszczególne funkcje w klasach wraz z sprawdzeniem ich skuteczności po połączeniu w wspólny program. To pozwoli nam w weekend skupić się na tworzeniu automatyzacji trenowania i testowania oraz na następnej interpretacji otrzymanych danych i wyborze optymalnych parametrów całego programu.\n",
    "\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "### Raport 2 (23.11.17 - 30.11.17)\n",
    "\n",
    "1. Zmiany w architekturze\n",
    "\n",
    "   W wyniku przemyśleń i występowania pewnych problemów postanowiliśmy zrezygnować z początkowego projektu klasy `ConfigurationManager`, w której użytkownik określa liczbę nagrań testowych (a w istocie osób, których nagrania miały być w całości testowe) na rzecz stałej konfiguracji leave-one-out, która wyklucza nagrania jednej osoby z procesu treningowego w każdej konfiguracji. Po tych poprawkach udało się zaimplementować działającą klasę `ConfigurationManager`, która z podanego folderu z danymi treningowymi tworzy słownik osób z przypisanymi im nagraniami i w metodach `training_data()` i `test_data()` zwraca odpowiednio wszystkie pliki z wyłączeniem jednej osoby (jej alfabetyczny indeks odpowiada numerowi konfiguracji `configuration_id`) i pliki nagrane przez osobę wybraną do testów kroswalidacji.\n",
    "    Zrezygnowaliśmy z klasy `GlobalParameters` na rzecz mniej zautomatyzowanego podejścia oraz z klasy `Recognizer` - ta ostatnia została zastąpiona różnymi odmianami pliku `main.py.`. W związku z problemami w używanych bibliotekach, usunięta została normalizacja danych w klasie WavFile.\n",
    "    \n",
    "2. Implementacja pętli treningowo-testowej\n",
    "\n",
    "   Główna pętla treningowo testowa, do której wprowadzaliśmy parametry i w wyniku której otrzymywaliśmy stopę błędu ErrorRate (% błędów z wszystkich konfiguracji) znajduje się w pliku `main.py`. W nim tworzone są wszystkie instancje klas naszego systemu z odpowiednimi parametrami.\n",
    "    Najpierw tworzony jest obiekt klasy `ConfigurationManager`, do którego przekazywana jest nazwa folderu z plikami testowymi. Następnie tworzona jest instancja klasy `MFCCParametrizer` z odpowiednimi parametrami.\n",
    "    Następnie w pętli zawierającej różne parametry sieci neuronowej tworzony był obiekt klasy `ANNClassifier`, który następnie był trenowany na danych dostarczonych przez instancję `ConfigurationManager`, odczytanych przez osobne obiekty `WavFile` i sparametryzowanych przez instancję `MFCCParametrizer`.\n",
    "    Pod koniec pętli to samo było wykonywane dla danych testowych z tym, że wywoływana była metoda `predict` klasyfikatora, a wyniki zapisywane były przez osobne obiekty klasy `ResultHandler` (jedna dla jednego zestawu parametrów sieci i klasyfikatora).\n",
    "    \n",
    "3. Zmiany parametrów sieci neuronowej\n",
    "\n",
    "   Pierwszymi parametrami, które wyznaczyliśmy, były funkcja aktywacji i optymalizator wag. Najlepszą kombinacją tych dwóch jest logistyczna funkcja aktywacji i optymalizator Adam. Następnie skupiliśmy się na liczbie warstw i neuronów w każdej warstwie. Z następującego wpisu: https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw zdecydowaliśmy się najpierw na jedną warstwę, a kiedy ją zoptymalizowaliśmy, dodaliśmy kolejną. Ostatecznie pierwsza warstwa ma 240, a druga 120 neuronów. Dodanie trzeciej warstwy pogarsza skuteczność systemu.\n",
    "   Próbowaliśmy dopasować parametr &alpha; i liczbę iteracji, ale żadne z nich nie dały znaczącej poprawy, więc przypisaliśmy im wartość domyślną.   \n",
    "   \n",
    "4. Zmiany ustawień parametryzacji MFCC\n",
    "\n",
    "    Manipulowaliśmy wartościami takimi jak długość okna, liczba współczynników, zakładkowanie i liftering. Jedynym parametrem, który ostatecznie zmieniliśmy z korzyścią dla wyników, było `appendEnergy=False` - można się spodziewać, że energia wszystkich nagrań będzie podobna i nie niesie ona istotnej informacji dla systemu, dlatego można z niej zrezygnować.\n",
    "      \n",
    "5. Serializacja\n",
    "    \n",
    "    Ostatnim krokiem było napisanie skryptu serializującego wyszkolony na wszystkich danych obiekt klasyfikatora i zapisanie go w pliku oraz skryptu deserializującego ten obiekt i używającego go w procesie rozpoznawania cyfr w podanych nagraniach. Na końcu nasz skrypt zapisuje wyniki do pliku .csv w zadanym przez prowadzącego formacie.\n",
    "    \n",
    "6. Podsumowanie wyników\n",
    "    \n",
    "    W testach kroswalidacji nasz system osiągnął stopę błędu poniżej 15%. Nie jest to zadowalający wynik, ale nie daliśmy rady dalej usprawnić systemu. Wydaje się, że jedyną możliwą do przeprowadzenia zmianą z korzyścią dla wyników byłoby użycie do treningu pojedynczych ramek zamiast superwektora. Największy problem wystąpił dla cyfr 9 i 5 - klasyfikator prawdopodobnie nie potrafił ustalić odpowiednich wag dla nich, gdyż zazwyczaj błędna odpowiedź dla jednej z nich polegała na wytypowaniu drugiej. Wynika to prawdopodobnie stąd, że \"dziewięć\" jest najdłuższym słowem w tym zbiorze (pod względem czasu wypowiadania), a uśredniony wektor MFCC wraz z macierzą kowariancji nie zawiera dokładnej informacji o przebiegu czasowym. Po usunięciu tej informacji brzmienia cyfr 5 i 9 stają sie bardzo zblizone do siebie, pod względem brzmienia nastepujących po sobie fonemów. \n",
    "    \n",
    "7. Werdykt\n",
    "   \n",
    "   System jest gotowy do zewnętrznych testów.\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
